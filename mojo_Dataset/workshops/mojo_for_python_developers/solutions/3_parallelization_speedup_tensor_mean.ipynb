{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2023 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from math import trunc, mod\n",
    "fn tensorprint[type: DType](t: Tensor[type])->None:\n",
    "    let rank = t.rank()\n",
    "    var dim0:Int=0\n",
    "    var dim1:Int=0\n",
    "    var dim2:Int=0\n",
    "    if rank==0 or rank>3:\n",
    "        print(\"Error: Tensor rank should be: 1,2, or 3. Tensor rank is \", rank)\n",
    "        return\n",
    "    if rank==1:\n",
    "        dim0 = 1\n",
    "        dim1 = 1\n",
    "        dim2 = t.dim(0)\n",
    "    if rank==2:\n",
    "        dim0 = 1\n",
    "        dim1 = t.dim(0)\n",
    "        dim2 = t.dim(1)\n",
    "    if rank==3:\n",
    "        dim0 = t.dim(0)\n",
    "        dim1 = t.dim(1)\n",
    "        dim2 = t.dim(2)\n",
    "    var val:SIMD[type, 1]=0.0\n",
    "    for i in range(dim0):\n",
    "        if i==0 and rank==3:\n",
    "            print(\"[\")\n",
    "        else:\n",
    "            if i>0:\n",
    "                print()\n",
    "        for j in range(dim1):\n",
    "            if rank!=1:\n",
    "                if j==0:\n",
    "                    print_no_newline(\"  [\")\n",
    "                else:\n",
    "                    print_no_newline(\"\\n   \")\n",
    "            print_no_newline(\"[\")\n",
    "            for k in range(dim2):\n",
    "                if rank==1:\n",
    "                    val = t[k]\n",
    "                if rank==2:\n",
    "                    val = t[j,k]\n",
    "                if rank==3:\n",
    "                    val = t[i,j,k]\n",
    "                let int_str: String\n",
    "                if val > 0 or val == 0:\n",
    "                    int_str = String(trunc(val).cast[DType.int32]())\n",
    "                else:\n",
    "                    val = -val\n",
    "                    int_str = \"-\"+String(trunc(val).cast[DType.int32]())\n",
    "                let float_str = String(mod(val,1))\n",
    "                let s = int_str+\".\"+float_str[2:6]\n",
    "                if k==0:\n",
    "                    print_no_newline(s)\n",
    "                else:\n",
    "                    print_no_newline(\"  \",s)\n",
    "            print_no_newline(\"]\")\n",
    "        if rank>1:\n",
    "            print_no_newline(\"]\")\n",
    "        print()\n",
    "    if rank==3:\n",
    "        print(\"]\")\n",
    "    print(\"Tensor shape:\",t.shape().__str__(),\", Tensor rank:\",rank,\",\",\"DType:\", type.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from math import trunc, mod\n",
    "from memory import memset_zero\n",
    "from sys.info import simdwidthof, simdbitwidth\n",
    "from algorithm import vectorize, parallelize, vectorize_unroll\n",
    "from utils.index import Index\n",
    "from random import rand, seed\n",
    "from python import Python\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMD bit width 128\n",
      "SIMD Width 4\n"
     ]
    }
   ],
   "source": [
    "alias dtype = DType.float32\n",
    "alias simd_width: Int = simdwidthof[dtype]()\n",
    "print(\"SIMD bit width\",simdbitwidth())\n",
    "print(\"SIMD Width\",simd_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [[0.0850   0.8916   0.1896   0.3980   0.7435   0.5603   0.8095   0.5117   0.9950   0.9666   0.4260   0.6529]\n",
      "   [0.9615   0.8579   0.2940   0.4146   0.5148   0.7897   0.5442   0.0936   0.4322   0.8449   0.7728   0.1918]\n",
      "   [0.7803   0.1813   0.5791   0.3141   0.4119   0.9923   0.1639   0.3348   0.0762   0.1745   0.0372   0.4674]\n",
      "   [0.6741   0.0667   0.3897   0.1653   0.9908   0.8706   0.6726   0.5877   0.2550   0.5930   0.2717   0.2704]\n",
      "   [0.0959   0.6325   0.1512   0.9488   0.0426   0.7350   0.4654   0.2225   0.5714   0.6045   0.6980   0.6646]]\n",
      "Tensor shape: 5x12 , Tensor rank: 2 , DType: float32\n"
     ]
    }
   ],
   "source": [
    "let tx = rand[dtype](5,12)\n",
    "tensorprint(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix shape: 1000x100000\n",
      "Reduced Matrix shape 1000x1\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "let t = rand[dtype](1000,100000)\n",
    "var result = Tensor[dtype](t.dim(0),1)\n",
    "\n",
    "print(\"Input Matrix shape:\",t.shape().__str__())\n",
    "print(\"Reduced Matrix shape\",result.shape().__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn tensor_mean[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var new_tensor = Tensor[dtype](t.dim(0),1)\n",
    "    for i in range(t.dim(0)):\n",
    "        for j in range(t.dim(1)):\n",
    "            new_tensor[i] += t[i,j]\n",
    "        new_tensor[i] /= t.dim(1)\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn tensor_mean_vectorize_parallelized[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var new_tensor = Tensor[dtype](t.dim(0),1)\n",
    "    @parameter\n",
    "    fn parallel_reduce_rows(idx1: Int)->None:\n",
    "        @parameter\n",
    "        fn vectorize_reduce_row[simd_width: Int](idx2: Int) -> None:\n",
    "            new_tensor[idx1] += t.simd_load[simd_width](idx1*t.dim(1)+idx2).reduce_add()\n",
    "        vectorize[2*simd_width,vectorize_reduce_row](t.dim(1))\n",
    "        new_tensor[idx1] /= t.dim(1)\n",
    "    parallelize[parallel_reduce_rows](t.dim(0),8)\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "let np = Python.import_module(\"numpy\")\n",
    "let dim0 = t.dim(0)\n",
    "let dim1 = t.dim(1)\n",
    "let t_np = np.random.rand(dim0,dim1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mojo naive mean: 363.02510000000001 ms\n",
      "Numpy mean: 22.256399999999999 ms\n",
      "Mojo Vectorized and parallelized mean: 12.950100000000001 ms\n"
     ]
    }
   ],
   "source": [
    "alias reps = 10\n",
    "var tm1 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = tensor_mean[dtype](t)\n",
    "let dur1 = time.now()-tm1\n",
    "print(\"Mojo naive mean:\",dur1/reps/1000000,\"ms\")\n",
    "\n",
    "var tm2 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = np.mean(t_np,1)\n",
    "let dur2 = time.now()-tm2\n",
    "print(\"Numpy mean:\",dur2/reps/1000000,\"ms\")\n",
    "\n",
    "var tm3 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = tensor_mean_vectorize_parallelized[dtype](t)\n",
    "let dur3 = time.now()-tm3\n",
    "print(\"Mojo Vectorized and parallelized mean:\",dur3/reps/1000000,\"ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
