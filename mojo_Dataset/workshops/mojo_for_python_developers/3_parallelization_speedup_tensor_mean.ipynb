{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2023 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up Python in MojoðŸ”¥ using vectorization and parallelization\n",
    "#### Example: Calculate row-wise `mean()` of a matrix by vectorizing across colums and parallelizing across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from math import trunc, mod\n",
    "from memory import memset_zero\n",
    "from sys.info import simdwidthof, simdbitwidth\n",
    "from algorithm import vectorize, parallelize, vectorize_unroll\n",
    "from utils.index import Index\n",
    "from random import rand, seed\n",
    "from python import Python\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias dtype = DType.float32\n",
    "alias simd_width: Int = simdwidthof[dtype]()\n",
    "print(\"SIMD bit width\",simdbitwidth())\n",
    "print(\"SIMD Width\",simd_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an small `Tensor` and visualize the shape of the inputs and outputs.\n",
    "For this small input matrix is `5x12` and the output matrix with `means()` should be `5x1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let tx = rand[dtype](5,12)\n",
    "tensorprint(tx) \n",
    "\n",
    "# Note: This function will give you an error. \n",
    "# Run the last cell in the notebook that defines `tensorprint` and then \n",
    "# come back and run this cell. The `tensorprint` is temporary helper function \n",
    "# untill we have native print support for tensors in the next release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `1000x100000` matrix to make it more computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "let t = rand[dtype](1000,100000)\n",
    "var result = Tensor[dtype](t.dim(0),1)\n",
    "\n",
    "print(\"Input Matrix shape:\",t.shape().__str__())\n",
    "print(\"Reduced Matrix shape\",result.shape().__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to calculate averages of each row the naive way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn tensor_mean[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var new_tensor = Tensor[dtype](t.dim(0),1)\n",
    "    for i in range(t.dim(0)):\n",
    "        for j in range(t.dim(1)):\n",
    "            new_tensor[i] += t[i,j]\n",
    "        new_tensor[i] /= t.dim(1)\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized and parallelized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn tensor_mean_vectorize_parallelized[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var new_tensor = Tensor[dtype](t.dim(0),1)\n",
    "    @parameter\n",
    "    fn parallel_reduce_rows(idx1: Int)->None:\n",
    "        @parameter\n",
    "        fn vectorize_reduce_row[simd_width: Int](idx2: Int) -> None:\n",
    "            new_tensor[idx1] += t.simd_load[simd_width](idx1*t.dim(1)+idx2).reduce_add()\n",
    "        vectorize[2*simd_width,vectorize_reduce_row](t.dim(1))\n",
    "        new_tensor[idx1] /= t.dim(1)\n",
    "    parallelize[parallel_reduce_rows](t.dim(0),8)\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive approach in Mojo\n",
    "alias reps = 10\n",
    "var tm1 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = tensor_mean[dtype](t)\n",
    "let dur1 = time.now()-tm1\n",
    "print(\"Mojo naive mean:\",dur1/reps/1000000,\"ms\")\n",
    "\n",
    "# NumPy approach \n",
    "let np = Python.import_module(\"numpy\")\n",
    "let dim0 = t.dim(0)\n",
    "let dim1 = t.dim(1)\n",
    "let t_np = np.random.rand(dim0,dim1).astype(np.float32)\n",
    "var tm2 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = np.mean(t_np,1)\n",
    "let dur2 = time.now()-tm2\n",
    "print(\"Numpy mean:\",dur2/reps/1000000,\"ms\")\n",
    "\n",
    "# Vectorized and parallelized approach in Mojo\n",
    "var tm3 = time.now()\n",
    "for i in range(reps):\n",
    "    _ = tensor_mean_vectorize_parallelized[dtype](t)\n",
    "let dur3 = time.now()-tm3\n",
    "print(\"Mojo Vectorized and parallelized mean:\",dur3/reps/1000000,\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorShape, TensorSpec\n",
    "from math import trunc, mod\n",
    "fn tensorprint[type: DType](t: Tensor[type])->None:\n",
    "    let rank = t.rank()\n",
    "    var dim0:Int=0\n",
    "    var dim1:Int=0\n",
    "    var dim2:Int=0\n",
    "    if rank==0 or rank>3:\n",
    "        print(\"Error: Tensor rank should be: 1,2, or 3. Tensor rank is \", rank)\n",
    "        return\n",
    "    if rank==1:\n",
    "        dim0 = 1\n",
    "        dim1 = 1\n",
    "        dim2 = t.dim(0)\n",
    "    if rank==2:\n",
    "        dim0 = 1\n",
    "        dim1 = t.dim(0)\n",
    "        dim2 = t.dim(1)\n",
    "    if rank==3:\n",
    "        dim0 = t.dim(0)\n",
    "        dim1 = t.dim(1)\n",
    "        dim2 = t.dim(2)\n",
    "    var val:SIMD[type, 1]=0.0\n",
    "    for i in range(dim0):\n",
    "        if i==0 and rank==3:\n",
    "            print(\"[\")\n",
    "        else:\n",
    "            if i>0:\n",
    "                print()\n",
    "        for j in range(dim1):\n",
    "            if rank!=1:\n",
    "                if j==0:\n",
    "                    print_no_newline(\"  [\")\n",
    "                else:\n",
    "                    print_no_newline(\"\\n   \")\n",
    "            print_no_newline(\"[\")\n",
    "            for k in range(dim2):\n",
    "                if rank==1:\n",
    "                    val = t[k]\n",
    "                if rank==2:\n",
    "                    val = t[j,k]\n",
    "                if rank==3:\n",
    "                    val = t[i,j,k]\n",
    "                let int_str: String\n",
    "                if val > 0 or val == 0:\n",
    "                    int_str = String(trunc(val).cast[DType.int32]())\n",
    "                else:\n",
    "                    val = -val\n",
    "                    int_str = \"-\"+String(trunc(val).cast[DType.int32]())\n",
    "                let float_str = String(mod(val,1))\n",
    "                let s = int_str+\".\"+float_str[2:6]\n",
    "                if k==0:\n",
    "                    print_no_newline(s)\n",
    "                else:\n",
    "                    print_no_newline(\"  \",s)\n",
    "            print_no_newline(\"]\")\n",
    "        if rank>1:\n",
    "            print_no_newline(\"]\")\n",
    "        print()\n",
    "    if rank==3:\n",
    "        print(\"]\")\n",
    "    print(\"Tensor shape:\",t.shape().__str__(),\", Tensor rank:\",rank,\",\",\"DType:\", type.__str__())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
