{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2023 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speedup Python implementation in Mojo for simple Euclidean distance calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we'll calculate the Euclidean distance between two n-dimensional vectors a and b mathematically expressed as the L2-norm of the difference vector: $$ ||a-b||_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating 2 random n-dimensional numpy arrays in python\n",
    "Notice that the cell starts with `%%python` i.e. this cell will execute in Python, no Mojo. We'll use this to compare performance between Python and Mojo implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import time\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from timeit import timeit\n",
    "\n",
    "n = 1000000\n",
    "np.random.seed(42)\n",
    "arr1_np = np.random.rand(n)\n",
    "arr2_np = np.random.rand(n)\n",
    "\n",
    "arr1_list = arr1_np.tolist()\n",
    "arr2_list = arr2_np.tolist()\n",
    "\n",
    "def print_result(name, value, seconds):\n",
    "    print(f\"=== {name} Performance ===\")\n",
    "    print(f\"value:     {value:.6f}\")\n",
    "    print(f\"time (ms): {seconds * 1000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a Python function which takes `arr1_list` and `arr2_list` as arguments and calculates the eculidean distance using the following steps:\n",
    "\n",
    "1. Calculate the element-wise difference between two vectors to create a difference vector\n",
    "2. Square each element in the difference vector\n",
    "3. Sum up all the squared elements of the difference vector\n",
    "4. Take the square root of the sum\n",
    "\n",
    "Go ahead and run the cell and take a note of the value and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Pure python iterative implementation\n",
    "def python_dist(a, b):\n",
    "    sq_dist = 0.0\n",
    "    n = len(a)\n",
    "    for i in range(n):\n",
    "        diff = a[i] - b[i]\n",
    "        sq_dist += diff * diff\n",
    "    return sqrt(sq_dist)\n",
    "\n",
    "secs = timeit(lambda: python_dist(arr1_list, arr2_list), number=5)/5\n",
    "print_result(\"Pure Python\", python_dist(arr1_list, arr2_list), secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare pure-Python performance with NumPy. NumPy takes advantage of optimized linear algebra subroutines to accelerate these calculations. Run the cell below and take a note of the speedup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "def python_numpy_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "secs = timeit(lambda: python_numpy_dist(arr1_np, arr2_np), number=5)/5\n",
    "print_result(\"NumPy\", python_numpy_dist(arr1_np, arr2_np), secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to MojoðŸ”¥!\n",
    "Run the following cell to copy over the numpy arrays from Python to MojoðŸ”¥ tensors so can compare not only the execution time but also verify the accuracy of the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from time import now\n",
    "from math import sqrt\n",
    "\n",
    "let n: Int = 1000000\n",
    "alias dtype = DType.float64\n",
    "var arr1_tensor = Tensor[dtype](n)\n",
    "var arr2_tensor = Tensor[dtype](n)\n",
    "\n",
    "for i in range(n):\n",
    "    arr1_tensor[i] = arr1_np[i].to_float64()\n",
    "    arr2_tensor[i] = arr2_np[i].to_float64()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Copy over the pure-Python function into MojoðŸ”¥ and variable declations and return types, you did in notebook 1. \n",
    "\n",
    "<details><summary><b>Solution</b></summary>\n",
    "<pre>\n",
    "fn mojo_dist(a: Tensor[dtype], b: Tensor[dtype]) -> Float64:\n",
    "    var sq_dist:Float64 = 0.0\n",
    "    let n = a.num_elements()\n",
    "    for i in range(n):\n",
    "        let diff = a[i]-b[i]\n",
    "        sq_dist += diff*diff\n",
    "    return sqrt(sq_dist)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: Insert function below with the following signature\n",
    "#fn mojo_dist(a: Tensor[dtype], b: Tensor[dtype]) -> Float64: ...\n",
    "\n",
    "let eval_begin = now()\n",
    "let mojo_arr_sum = mojo_dist(arr1_tensor, arr2_tensor)\n",
    "let eval_end = now()\n",
    "\n",
    "print_result(\"Mojo\", mojo_arr_sum, Float64(eval_end - eval_begin) / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerating MojoðŸ”¥ code with Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern CPU cores have dedicated vector register that can perform calculations simultaneously on fixed length vector data. For example an Intel CPU with AVX 512 has 512-bit vector register, therefore we have `512/64=8` Float64 elements on which we can simultaneously perform calculations. This is referred to as `SIMD = Single Instruction Multiple Data`. The theoretical speed up is 8x but in practice it'll be lower due to memory reads/writes latency.\n",
    "\n",
    "Note: SIMD is should not be confused with parallel processing with multiple cores/threads. Each core has dedicated SIMD vector units and we can take advantage of both SIMD and parallel processing to see massive speedup as you'll see in notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's gather the `simd_width` for specific `dtype` on the specific CPU you'll be running this on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys.info import simdwidthof\n",
    "from algorithm import vectorize\n",
    "\n",
    "alias simd_width = simdwidthof[DType.float64]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vectorize our naive `mojo_dist` function, we'll write a closure that is parameterized on `simd_width`. Rather than operate on individual elements, we'll work with `simd_width` elements which gives us speed ups. You can access `simd_width` elements using `simd_load`.\n",
    "\n",
    "Given that this is a complex topic, I've provided the solution below, please raise your hand and ask the instructor for explainations if anything is unclear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn mojo_dist_vectorized(a: Tensor[DType.float64], b: Tensor[DType.float64]) -> Float64:\n",
    "    var sq_dist: Float64 = 0.0\n",
    "    @parameter\n",
    "    fn simd_norm[simd_width:Int](idx:Int):\n",
    "        let diff = a.simd_load[simd_width](idx) - b.simd_load[simd_width](idx)\n",
    "        sq_dist += (diff * diff).reduce_add()\n",
    "    vectorize[simd_width, simd_norm](a.num_elements())\n",
    "    return sqrt(sq_dist)\n",
    "\n",
    "let eval_begin = now()\n",
    "let mojo_arr_vec_sum = mojo_dist_vectorized(arr1_tensor, arr2_tensor)\n",
    "let eval_end = now()\n",
    "\n",
    "print_result(\"Mojo Vectorized\", mojo_arr_vec_sum, (eval_end - eval_begin) / 1e9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
