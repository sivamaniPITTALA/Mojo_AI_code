{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's new in MojoðŸ”¥ SDK v0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from algorithm import vectorize\n",
    "\n",
    "struct SquareMatrix[dtype: DType = DType.float32, dim: Int = 4]():\n",
    "  var mat: Tensor[dtype]\n",
    "\n",
    "  fn __init__(inout self, val: SIMD[dtype,1] = 5):\n",
    "    self.mat = Tensor[dtype](self.dim,self.dim)\n",
    "    alias simd_width = simdwidthof[dtype]()\n",
    "    @parameter\n",
    "    fn fill_val[simd_width: Int](idx: Int) -> None:\n",
    "        self.mat.simd_store(idx, self.mat.simd_load[simd_width](idx).splat(val))\n",
    "    vectorize[simd_width, fill_val](self.mat.num_elements())\n",
    "\n",
    "  fn __getitem__(self,x:Int,y:Int)->SIMD[dtype,1]:\n",
    "    return self.mat[x,y]\n",
    "\n",
    "  fn print(self):\n",
    "    print(self.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquareMatrix().print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquareMatrix(val=12).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquareMatrix[DType.float64](10).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquareMatrix[DType.float64,dim=3](1).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquareMatrix[dtype=DType.float64,dim=3](val=1.5).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword argument in `__getitem__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let sm = SquareMatrix()\n",
    "sm.print()\n",
    "\n",
    "print()\n",
    "print('Keyword argument in __getitem__()')\n",
    "print(sm[x=0, y=3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic parameterization of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters are automatically added as input parameters on the function\n",
    "* Function argument input parameters can now be referenced within the signature of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import mul\n",
    "fn multiply(sm: SquareMatrix, val: SIMD[sm.dtype,1]) -> Tensor[sm.dtype]:\n",
    "    alias simd_width: Int = simdwidthof[sm.dtype]()\n",
    "    let result_tensor = Tensor[sm.dtype](sm.mat.shape())\n",
    "\n",
    "    @parameter\n",
    "    fn vectorize_multiply[simd_width: Int](idx: Int) -> None:\n",
    "        result_tensor.simd_store[simd_width](idx, mul[sm.dtype,simd_width](sm.mat.simd_load[simd_width](idx),val))\n",
    "    vectorize[simd_width, vectorize_multiply](sm.mat.num_elements())\n",
    "    return result_tensor\n",
    "\n",
    "fn main():\n",
    "    let sm = SquareMatrix(5)\n",
    "    let res = multiply(sm,100.0)\n",
    "    print(res)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save Tensors + String enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from algorithm import vectorize\n",
    "from time import now\n",
    "from memory import memcpy\n",
    "\n",
    "struct SquareMatrix[dtype: DType = DType.float32, dim: Int = 4]():\n",
    "  var mat: Tensor[dtype]\n",
    "\n",
    "  fn __init__(inout self, val:SIMD[dtype,1] = 5):\n",
    "    self.mat = Tensor[dtype](self.dim,self.dim)\n",
    "    alias simd_width = simdwidthof[dtype]()\n",
    "    @parameter\n",
    "    fn fill_val[simd_width: Int](idx: Int) -> None:\n",
    "        self.mat.simd_store(idx, self.mat.simd_load[simd_width](idx).splat(val))\n",
    "    vectorize[simd_width, fill_val](self.mat.num_elements())\n",
    "\n",
    "  fn print(self):\n",
    "    print(self.mat)\n",
    "\n",
    "  fn prepare_filename(self, fname: String)->String:\n",
    "    var fpath = fname\n",
    "    if fpath.count('.') < 2:\n",
    "        fpath += '.data'\n",
    "    fpath = fpath.replace(\".\",\"_\"+self.mat.spec().__str__()+\".\")\n",
    "    if fpath.find('/'):\n",
    "        fpath = './'+fpath\n",
    "    return fpath\n",
    "\n",
    "  fn save(self, fname: String='saved_matrix') raises -> String:\n",
    "    let fpath = self.prepare_filename(fname)\n",
    "    self.mat.tofile(fpath)\n",
    "    print('File saved:',fpath)\n",
    "    return fpath\n",
    "\n",
    "  @staticmethod\n",
    "  fn load[dtype: DType,dim: Int](fpath:String) raises -> Tensor[dtype]:\n",
    "    let load_mat = Tensor[dtype].fromfile(fpath)\n",
    "    let new_tensor = Tensor[dtype](dim,dim)\n",
    "    memcpy(new_tensor.data(),load_mat.data(),load_mat.num_elements())\n",
    "    _ = load_mat\n",
    "    return new_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let m = SquareMatrix()\n",
    "m.print()\n",
    "let fpath = m.save('saved_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Tensor from file:',fpath)\n",
    "print()\n",
    "let load_mat = SquareMatrix.load[DType.float32,4](fpath)\n",
    "print(load_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark row-wise `mean()` of a matrix by vectorizing across colums and parallelizing across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import rand\n",
    "let tx = rand[DType.float32](5,7)\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "from random import rand\n",
    "import benchmark\n",
    "from time import sleep\n",
    "from algorithm import vectorize, parallelize\n",
    "\n",
    "alias dtype = DType.float32\n",
    "alias simd_width = simdwidthof[DType.float32]()\n",
    "\n",
    "fn row_mean_naive[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var res = Tensor[dtype](t.dim(0),1)\n",
    "    for i in range(t.dim(0)):\n",
    "        for j in range(t.dim(1)):\n",
    "            res[i] += t[i,j]\n",
    "        res[i] /= t.dim(1)\n",
    "    return res\n",
    "\n",
    "fn row_mean_fast[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
    "    var res = Tensor[dtype](t.dim(0),1)\n",
    "    @parameter\n",
    "    fn parallel_reduce_rows(idx1: Int)->None:\n",
    "        @parameter\n",
    "        fn vectorize_reduce_row[simd_width: Int](idx2: Int) -> None:\n",
    "            res[idx1] += t.simd_load[simd_width](idx1*t.dim(1)+idx2).reduce_add()\n",
    "        vectorize[2*simd_width,vectorize_reduce_row](t.dim(1))\n",
    "        res[idx1] /= t.dim(1)\n",
    "    parallelize[parallel_reduce_rows](t.dim(0),t.dim(0))\n",
    "    return res\n",
    "\n",
    "fn main():\n",
    "    let t = rand[dtype](1000,100000)\n",
    "    var result = Tensor[dtype](t.dim(0),1)\n",
    "\n",
    "    @parameter\n",
    "    fn bench_mean():\n",
    "        _ = row_mean_naive(t)\n",
    "    \n",
    "    @parameter\n",
    "    fn bench_mean_fast():\n",
    "        _ = row_mean_fast(t)\n",
    "\n",
    "    let report = benchmark.run[bench_mean]()\n",
    "    let report_fast = benchmark.run[bench_mean_fast]()\n",
    "    report.print()\n",
    "    report_fast.print()\n",
    "    print(\"Speed up:\",report.mean()/report_fast.mean())\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMD enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    alias dtype = DType.float32\n",
    "    alias simd_width = simdwidthof[DType.float32]()\n",
    "\n",
    "    let a = SIMD[dtype].splat(0.5)\n",
    "    let b = SIMD[dtype].splat(2.5) \n",
    "\n",
    "    print(\"SIMD a:\",a)\n",
    "    print(\"SIMD b:\",b)\n",
    "    print()\n",
    "    print(\"SIMD a.join(b):\",a.join(b))\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
