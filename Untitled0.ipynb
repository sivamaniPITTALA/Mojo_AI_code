{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORXCNs+x1YsiygFc90I7Gw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MljL5bhGgdmY"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the path to your dataset in Google Colab\n","dataset_path = \"/content/drive/MyDrive/mojo_ai/mojo_ai_code/mojo_Dataset\"\n","\n","# Upload the Mojo_AI_code folder (zip it if needed)\n","# You can comment out the following lines if you've already uploaded the dataset manually.\n","code_path = \"/content/drive/MyDrive/mojo_ai/mojo_ai_code\"\n","\n","# Initialize empty lists to store text and labels\n","texts = []\n","labels = []\n","\n","# Loop through each folder (examples, proposals, user, workshops)\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Loop through each file in the folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read the content of the file\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append the content to the texts list and the folder name to the labels list\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences for fixed input size\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])  # Convert to NumPy array\n","\n","# Build a basic NLP model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_seq_length),\n","    tf.keras.layers.LSTM(50),\n","    tf.keras.layers.Dense(len(label_mapping), activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(padded_sequences, numerical_labels, epochs=10, batch_size=32)\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/mojo_ai/mojo_ai_code/mojo_ai_model.h5')\n","\n","# User interaction and reinforcement learning\n","user_folder_path = os.path.join(dataset_path, \"user\")\n","data_file_path = os.path.join(user_folder_path, \"data\")\n","\n","# Simulate user interaction (replace this with your actual user interaction mechanism)\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Store the user question and answer\n","user_data = [f\"{user_question}\\t{user_answer}\\n\"]\n","\n","# Save the updated user data\n","with open(data_file_path, 'w', encoding='utf-8') as user_data_file:\n","    user_data_file.writelines(user_data)\n","\n","# Now, you can use this updated user data for reinforcement learning.\n","# Load the model\n","loaded_model = tf.keras.models.load_model('/content/mojo_ai_model.h5')\n","\n","# Tokenize the new user data\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert the label to numerical format\n","user_label = label_mapping[\"user\"]\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, np.array([user_label]), epochs=5, batch_size=1)\n"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the path to your dataset in Google Colab\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","\n","# Initialize empty lists to store text and labels\n","texts = []\n","labels = []\n","\n","# Loop through each folder (examples, proposals, user, workshops)\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Loop through each file in the folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read the content of the file\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append the content to the texts list and the folder name to the labels list\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences for fixed input size\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","# Build a CNN-LSTM model\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 50\n","\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n","model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n","model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","model.add(tf.keras.layers.LSTM(50))\n","model.add(tf.keras.layers.Dense(len(label_mapping), activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(padded_sequences, numerical_labels, epochs=10, batch_size=32)\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5')\n","\n","# Simulate user interaction and continue training (if needed)\n","# user_question = \"How does Mojo handle interop with Python?\"\n","# user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# user_sequences = tokenizer.texts_to_sequences([user_question])\n","# user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","# user_label = label_mapping[\"user\"]\n","\n","# model.fit(user_padded_sequences, np.array([user_label]), epochs=5, batch_size=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":664},"id":"8EzFUfByiDdB","executionInfo":{"status":"error","timestamp":1699948225606,"user_tz":-330,"elapsed":4318793,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"0ae5c793-3a6c-4f25-94ce-30212faff89a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/10\n","2/2 [==============================] - 429s 201s/step - loss: 1.1007 - accuracy: 0.2609\n","Epoch 2/10\n","2/2 [==============================] - 407s 203s/step - loss: 1.0733 - accuracy: 0.6957\n","Epoch 3/10\n","2/2 [==============================] - 404s 187s/step - loss: 1.0463 - accuracy: 0.6957\n","Epoch 4/10\n","2/2 [==============================] - 399s 183s/step - loss: 1.0139 - accuracy: 0.6957\n","Epoch 5/10\n","2/2 [==============================] - 441s 229s/step - loss: 0.9709 - accuracy: 0.6957\n","Epoch 6/10\n","2/2 [==============================] - 476s 240s/step - loss: 0.9179 - accuracy: 0.6957\n","Epoch 7/10\n","2/2 [==============================] - 457s 223s/step - loss: 0.8613 - accuracy: 0.6957\n","Epoch 8/10\n","2/2 [==============================] - 478s 229s/step - loss: 0.8248 - accuracy: 0.6957\n","Epoch 9/10\n","2/2 [==============================] - 454s 214s/step - loss: 0.8406 - accuracy: 0.6957\n","Epoch 10/10\n","2/2 [==============================] - 466s 236s/step - loss: 0.8374 - accuracy: 0.6957\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2f21e88f05f1>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0muser_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_question\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0muser_padded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0muser_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'user'"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the path to your dataset in Google Colab\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","\n","# Initialize empty lists to store text and labels\n","texts = []\n","labels = []\n","\n","# Loop through each folder (examples, proposals, user, workshops)\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Loop through each file in the folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read the content of the file\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append the content to the texts list and the folder name to the labels list\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences for fixed input size\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","# Build a CNN-LSTM model\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 50  # Replace with your sequence length\n","\n","# Load the model\n","loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5')\n","\n","# Simulate user interaction (replace with actual user interaction mechanism)\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Tokenize the new user data (assuming tokenizer exists)\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Ensure 'user' is mapped in label_mapping\n","if \"user\" not in label_mapping:\n","    label_mapping[\"user\"] = len(label_mapping)\n","\n","# Map 'user' label to a numerical value\n","user_label = np.array([label_mapping[\"user\"]])\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, user_label, epochs=5, batch_size=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hmuy-ncx3LNg","executionInfo":{"status":"error","timestamp":1699950226898,"user_tz":-330,"elapsed":11399,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"ebe115bb-c88a-486e-f1ce-e028ddc71322"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/5\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-9ce7a83b8ea8>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Continue training with the new user data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-11-9ce7a83b8ea8>\", line 74, in <cell line: 74>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 3\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_12617]"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the path to your dataset in Google Colab\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","\n","# Initialize empty lists to store text and labels\n","texts = []\n","labels = []\n","\n","# Loop through each folder (examples, proposals, user, workshops)\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Loop through each file in the folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read the content of the file\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append the content to the texts list and the folder name to the labels list\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences for fixed input size\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","# Build a CNN-LSTM model\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 50\n","\n","# Simulate user interaction (replace with actual user interaction mechanism)\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Tokenize the new user data\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Ensure 'user' is mapped in label_mapping\n","if \"user\" not in label_mapping:\n","    label_mapping[\"user\"] = len(label_mapping)\n","else:  # Map 'user' label to a numerical value\n","    print(label_mapping)\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, np.array([label_mapping[\"user\"]]), epochs=5, batch_size=1)\n","\n","# Save the updated model\n","loaded_model.save('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_retrained.h5')\n","\n","# Store user question and response in data.txt file\n","data_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/data.txt'\n","with open(data_path, 'a') as file:\n","    file.write(f\"{user_question}\\t{user_answer}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"99hnvhhQ7FHB","executionInfo":{"status":"error","timestamp":1699957735032,"user_tz":-330,"elapsed":67611,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"206ff3bf-057e-4c67-bf94-0df7119fecd1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0b871caf9482>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Continue training with the new user data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Save the updated model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'loaded_model' is not defined"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","data_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","\n","# Initialize lists for text and labels\n","texts = []\n","labels = []\n","\n","# List of folders\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","# Read data from folders\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Read files in each folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read file content\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append content to texts and folder name to labels\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences and pad sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","# Load the model\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Simulate user interaction\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Tokenize user data\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Ensure 'user' is mapped in label_mapping\n","if \"user\" not in label_mapping:\n","    label_mapping[\"user\"] = len(label_mapping)\n","    num_classes = len(label_mapping)  # Update the number of classes\n","else:  # Map 'user' label to a numerical value\n","    print(label_mapping)\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, np.array([label_mapping[\"user\"]]), epochs=5, batch_size=1)\n","\n","# Save the updated model\n","loaded_model.save('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_retrained.h5')\n","\n","# Store user question and response in data.txt file\n","with open(data_path, 'a') as file:\n","    file.write(f\"{user_question}\\t{user_answer}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ATdKHJD6YTei","executionInfo":{"status":"error","timestamp":1699958039254,"user_tz":-330,"elapsed":10116,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"df2d341c-ab0c-4ec0-ecea-6eb1bcda1310"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/5\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-1d9c78c20ead>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Continue training with the new user data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Save the updated model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-5-1d9c78c20ead>\", line 73, in <cell line: 73>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 3\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_5986]"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","data_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","\n","# Initialize lists for text and labels\n","texts = []\n","labels = []\n","\n","# List of folders\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","# Read data from folders\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Read files in each folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read file content\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append content to texts and folder name to labels\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences and pad sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","# Load the model\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Simulate user interaction\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Tokenize user data\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Ensure 'user' is mapped in label_mapping\n","if \"user\" not in label_mapping:\n","    label_mapping[\"user\"] = len(label_mapping)\n","\n","# Compile the model with categorical cross-entropy loss\n","loaded_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n","                     optimizer=tf.keras.optimizers.Adam(),\n","                     metrics=['accuracy'])\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, np.array([label_mapping[\"user\"]]), epochs=5, batch_size=1)\n","\n","# Save the updated model\n","loaded_model.save('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_retrained.h5')\n","\n","# Store user question and response in data.txt file\n","with open(data_path, 'a') as file:\n","    file.write(f\"{user_question}\\t{user_answer}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"id":"xXoJBAguZ2PE","executionInfo":{"status":"error","timestamp":1699958197998,"user_tz":-330,"elapsed":7307,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"cf220620-fd20-4eab-e529-e7006d7b5516"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/5\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f82adca9b378>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Continue training with the new user data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Save the updated model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (1, 1) and (1, 3) are incompatible\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","from google.colab import drive\n","import pickle\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","data_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","\n","# Initialize lists for text and labels\n","texts = []\n","labels = []\n","\n","# List of folders\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","# Read data from folders\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Read files in each folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read file content\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append content to texts and folder name to labels\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","# Convert text to sequences and pad sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","# Save variables to a file using pickle\n","data_to_save = {\n","    'texts': texts,\n","    'max_seq_length': max_seq_length,\n","    'padded_sequences': padded_sequences\n","}\n","\n","file_path_to_save = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/content_of_ds.pkl\"\n","with open(file_path_to_save, 'wb') as f:\n","    pickle.dump(data_to_save, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWI1iRmLaPgx","executionInfo":{"status":"ok","timestamp":1699959442371,"user_tz":-330,"elapsed":5224,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"3381eb63-a97c-4285-a996-7e2e5221120b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Load the trained model\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","loaded_model = load_model(model_path)\n","\n","# Function to preprocess user input\n","def preprocess_input(user_input, tokenizer, max_length):\n","    # Tokenize the user input\n","    sequence = tokenizer.texts_to_sequences([user_input])\n","    # Pad sequences\n","    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n","    return padded_sequence\n","\n","# Load tokenizer and max sequence length\n","# You might need to adapt this based on how you saved these values earlier\n","tokenizer_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/content_of_ds.pkl'\n","max_length = 10000  # Update this with your actual max sequence length\n","\n","# Load tokenizer (you need to implement this loading part if you saved it in a pickle file)\n","# tokenizer = load_tokenizer(tokenizer_path)\n","\n","# Get user input\n","user_question = input(\"Enter your question: \")\n","\n","# Preprocess user input\n","user_padded_sequence = preprocess_input(user_question, tokenizer, max_length)\n","\n","# Generate the model's response\n","predicted_probabilities = loaded_model.predict(user_padded_sequence)\n","predicted_label = np.argmax(predicted_probabilities)  # Get the class with the highest probability\n","\n","# Display the response to the user\n","response = label_mapping_inverse[predicted_label]  # Assuming you have a label mapping\n","print(\"Model's response:\", response)\n","\n","# Store the question and response into a file\n","data_file_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","with open(data_file_path, 'a') as file:\n","    file.write(f\"Question: {user_question}\\n\")\n","    file.write(f\"Response: {response}\\n\")\n","    file.write(\"-\" * 20 + \"\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":789},"id":"W5Eo40Gqf0Fc","executionInfo":{"status":"error","timestamp":1699959913298,"user_tz":-330,"elapsed":7755,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"929487f5-a89f-4a95-cea1-450e0e95f784"},"execution_count":17,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your question: what is mojo\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-07bc47f8b924>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Generate the model's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mpredicted_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_probabilities\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the class with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 64986), found shape=(None, 10000)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","# Load the trained model\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","loaded_model = load_model(model_path)\n","\n","# Load tokenizer and max sequence length\n","tokenizer_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/content_of_ds.pkl'\n","max_length = 10000  # Update this with your actual max sequence length\n","\n","# Load tokenizer\n","tokenizer = Tokenizer()\n","with open(tokenizer_path, 'rb') as f:\n","    tokenizer = pickle.load(f)\n","\n","# Function to preprocess user input\n","def preprocess_input(user_input, tokenizer, max_length):\n","    # Tokenize the user input\n","    sequence = tokenizer.texts_to_sequences([user_input])\n","    # Pad sequences\n","    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n","    return padded_sequence\n","\n","# Get user input\n","user_question = input(\"Enter your question: \")\n","\n","# Preprocess user input\n","user_padded_sequence = preprocess_input(user_question, tokenizer, max_length)\n","\n","# Generate the model's response\n","predicted_probabilities = loaded_model.predict(user_padded_sequence)\n","predicted_label = np.argmax(predicted_probabilities)  # Get the class with the highest probability\n","\n","# Define your label mapping (Replace this with your actual label mapping)\n","label_mapping = {0: 'label_1', 1: 'label_2', 2: 'label_3'}  # Example label mapping\n","\n","# Display the response to the user\n","predicted_class = label_mapping[predicted_label]\n","print(\"Model's predicted class:\", predicted_class)\n","\n","# Store the question and response into a file\n","data_file_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","with open(data_file_path, 'a') as file:\n","    file.write(f\"Question: {user_question}\\n\")\n","    file.write(f\"Predicted Response: {predicted_class}\\n\")\n","    file.write(\"-\" * 20 + \"\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"_JAOItbqg0m0","executionInfo":{"status":"error","timestamp":1699960109553,"user_tz":-330,"elapsed":14376,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"524658ed-d683-4d9a-ad99-34975be60fcf"},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your question: Can you provide an example of using loops in Mojo?\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-cf91ae171805>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Preprocess user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0muser_padded_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Generate the model's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-cf91ae171805>\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(user_input, tokenizer, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Tokenize the user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Pad sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpadded_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'texts_to_sequences'"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset\"\n","code_path = \"/content/drive/MyDrive/mojoai/Mojo_AI_code\"\n","data_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_Dataset/User/data.txt'\n","model_path = '/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5'\n","\n","# Initialize lists for text and labels\n","texts = []\n","labels = []\n","\n","# List of folders\n","folders = [\"examples\", \"proposals\", \"user\", \"workshops\"]\n","\n","# Read data from folders\n","for folder in folders:\n","    folder_path = os.path.join(dataset_path, folder)\n","\n","    # Read files in each folder\n","    for root, dirs, files in os.walk(folder_path):\n","        for filename in files:\n","            file_path = os.path.join(root, filename)\n","\n","            # Read file content\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","            # Append content to texts and folder name to labels\n","            texts.append(content)\n","            labels.append(folder)\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert text to sequences and pad sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","max_seq_length = max(map(len, sequences))\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","\n","# Convert labels to numerical format\n","label_mapping = {label: index for index, label in enumerate(set(labels))}\n","numerical_labels = np.array([label_mapping[label] for label in labels])\n","\n","max_seq_length = 100  # Replace with your sequence length\n","\n","# Load the model\n","loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/mojoai/Mojo_AI_code/mojo_ai_model_cnn_lstm.h5')\n","\n","# Simulate user interaction (replace with actual user interaction mechanism)\n","user_question = \"How does Mojo handle interop with Python?\"\n","user_answer = \"Mojo uses a Python API for seamless interop.\"\n","\n","# Tokenize the new user data (assuming tokenizer exists)\n","user_sequences = tokenizer.texts_to_sequences([user_question])\n","user_padded_sequences = pad_sequences(user_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Ensure 'user' is mapped in label_mapping\n","if \"user\" not in label_mapping:\n","    label_mapping[\"user\"] = len(label_mapping)\n","\n","# Map 'user' label to a numerical value\n","user_label = np.array([label_mapping[\"user\"]])\n","\n","# Continue training with the new user data\n","loaded_model.fit(user_padded_sequences, user_label, epochs=5, batch_size=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":650},"id":"OMDP_7HMhvKm","executionInfo":{"status":"error","timestamp":1699960352088,"user_tz":-330,"elapsed":4954,"user":{"displayName":"Sivamani Pittala","userId":"06003029961209614113"}},"outputId":"80f49afd-e518-4e99-f1b6-dd80a545e15c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/5\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-596d30d9c391>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Continue training with the new user data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_padded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 64986), found shape=(1, 100)\n"]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"LVT3Q7pk2KZU"}}]}